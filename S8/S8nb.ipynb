{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from model import BN\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional  as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_datasets=datasets.CIFAR10(root= './data_CIFAR10', \n",
    "                                transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                train=True, download=True)\n",
    "test_datasets = datasets.CIFAR10(root='./data_CIFAR10', \n",
    "                                 transform = transforms.Compose([transforms.ToTensor()]),\n",
    "                                 train=False, download = True)\n",
    "train_loader = DataLoader(dataset = train_datasets, batch_size=128, shuffle=True, num_workers=5, pin_memory=True)\n",
    "test_loader = DataLoader(dataset = test_datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def train(device, model, train_loader, optimizer, epoch):\n",
    "    model.train() # access model in train model\n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    pbar = tqdm(train_loader)\n",
    "    for idx , data in enumerate(pbar):\n",
    "        input , label = data\n",
    "        input.to(device)\n",
    "        label.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        pred = torch.argmax(output,dim=1)\n",
    "        acc=pred.eq(label).sum()/input.shape[0]\n",
    "        accuracies.append(acc)\n",
    "        # print(output.shape)\n",
    "        loss  = F.nll_loss(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    avg_acc = sum(accuracies)/len(accuracies)\n",
    "    print (f'at epoch:{epoch} avg_loss:{avg_loss},avg_train_acc:{avg_acc}')\n",
    "\n",
    "def test(device, model, test_loader):\n",
    "    model.eval() # access model in evaluation mode # set drop out and BN off\n",
    "    accuracies=[]\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            input , label = data\n",
    "            input.to(device)\n",
    "            label.to(device)\n",
    "            out = model(input)\n",
    "            pred = torch.argmax(out, dim=1)\n",
    "            acc= pred.eq(label).sum()/input.shape[0]\n",
    "            accuracies.append(acc)\n",
    "        avg_acc = np.mean(accuracies)\n",
    "        print (f'avg_test_acc:{avg_acc}')\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 30, 30]             448\n",
      "              ReLU-2           [-1, 16, 30, 30]               0\n",
      "       BatchNorm2d-3           [-1, 16, 30, 30]              32\n",
      "            Conv2d-4           [-1, 16, 28, 28]           2,320\n",
      "              ReLU-5           [-1, 16, 28, 28]               0\n",
      "       BatchNorm2d-6           [-1, 16, 28, 28]              32\n",
      "            Conv2d-7           [-1, 16, 26, 26]           2,320\n",
      "              ReLU-8           [-1, 16, 26, 26]               0\n",
      "       BatchNorm2d-9           [-1, 16, 26, 26]              32\n",
      "        MaxPool2d-10           [-1, 16, 13, 13]               0\n",
      "           Conv2d-11           [-1, 16, 11, 11]           2,320\n",
      "             ReLU-12           [-1, 16, 11, 11]               0\n",
      "      BatchNorm2d-13           [-1, 16, 11, 11]              32\n",
      "           Conv2d-14             [-1, 16, 9, 9]           2,320\n",
      "             ReLU-15             [-1, 16, 9, 9]               0\n",
      "      BatchNorm2d-16             [-1, 16, 9, 9]              32\n",
      "           Conv2d-17             [-1, 16, 7, 7]           2,320\n",
      "             ReLU-18             [-1, 16, 7, 7]               0\n",
      "      BatchNorm2d-19             [-1, 16, 7, 7]              32\n",
      "           Conv2d-20             [-1, 10, 7, 7]             170\n",
      "        AvgPool2d-21             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 12,410\n",
      "Trainable params: 12,410\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 1.04\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chourasi/ERA/S5/ERA/S8/model.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "model = BN()\n",
    "model.to(device)\n",
    "summary(model, input_size=(3,32,32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:14<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:0 avg_loss:1.5708646774291992,avg_train_acc:0.42879635095596313\n",
      "avg_test_acc:0.4756724536418915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:15<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:1 avg_loss:1.2035819292068481,avg_train_acc:0.5715792775154114\n",
      "avg_test_acc:0.5825751423835754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:2 avg_loss:1.0906327962875366,avg_train_acc:0.6123201847076416\n",
      "avg_test_acc:0.5915743708610535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:18<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:3 avg_loss:1.021903157234192,avg_train_acc:0.6395699977874756\n",
      "avg_test_acc:0.6108583807945251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:14<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:4 avg_loss:0.978256344795227,avg_train_acc:0.6550431847572327\n",
      "avg_test_acc:0.6284612417221069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:14<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:5 avg_loss:0.9490852952003479,avg_train_acc:0.6650655269622803\n",
      "avg_test_acc:0.6393393874168396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:14<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:6 avg_loss:0.919723391532898,avg_train_acc:0.6767224073410034\n",
      "avg_test_acc:0.6431962251663208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:12<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:7 avg_loss:0.9012612700462341,avg_train_acc:0.6810941100120544\n",
      "avg_test_acc:0.6539754867553711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:13<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:8 avg_loss:0.8826067447662354,avg_train_acc:0.6908447742462158\n",
      "avg_test_acc:0.6576344966888428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:12<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:9 avg_loss:0.8662020564079285,avg_train_acc:0.6937659978866577\n",
      "avg_test_acc:0.665249228477478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:11<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:10 avg_loss:0.8486693501472473,avg_train_acc:0.6995804309844971\n",
      "avg_test_acc:0.6650514006614685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:12<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:11 avg_loss:0.8371713161468506,avg_train_acc:0.7060022354125977\n",
      "avg_test_acc:0.6747428774833679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:17<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:12 avg_loss:0.8246555924415588,avg_train_acc:0.7069413065910339\n",
      "avg_test_acc:0.6599090099334717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:17<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:13 avg_loss:0.8174135684967041,avg_train_acc:0.7107256650924683\n",
      "avg_test_acc:0.6785996556282043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:11<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:14 avg_loss:0.8097710609436035,avg_train_acc:0.7161844968795776\n",
      "avg_test_acc:0.6798852682113647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:12<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:15 avg_loss:0.7965735197067261,avg_train_acc:0.718897819519043\n",
      "avg_test_acc:0.6815664768218994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:10<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:16 avg_loss:0.7897279262542725,avg_train_acc:0.7215233445167542\n",
      "avg_test_acc:0.6950158476829529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:12<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:17 avg_loss:0.7824083566665649,avg_train_acc:0.7225543260574341\n",
      "avg_test_acc:0.6850277185440063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:12<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:18 avg_loss:0.7763996720314026,avg_train_acc:0.7261629104614258\n",
      "avg_test_acc:0.6873022317886353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:11<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch:19 avg_loss:0.7722100019454956,avg_train_acc:0.7293718457221985\n",
      "avg_test_acc:0.6793908476829529\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "optimizer = optim.SGD(model.parameters(), lr=.01, momentum=0.9)\n",
    "for e in range(epochs):\n",
    "    train(device, model, train_loader, optimizer, e)\n",
    "    test(device, model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-era",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
